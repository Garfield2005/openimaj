<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html lang="en">
<head>
<title>Source code</title>
<link rel="stylesheet" type="text/css" href="../../../../../../../stylesheet.css" title="Style">
</head>
<body>
<div class="sourceContainer">
<pre><span class="sourceLineNo">001</span>/**<a name="line.1"></a>
<span class="sourceLineNo">002</span> * Copyright (c) 2011, The University of Southampton and the individual contributors.<a name="line.2"></a>
<span class="sourceLineNo">003</span> * All rights reserved.<a name="line.3"></a>
<span class="sourceLineNo">004</span> *<a name="line.4"></a>
<span class="sourceLineNo">005</span> * Redistribution and use in source and binary forms, with or without modification,<a name="line.5"></a>
<span class="sourceLineNo">006</span> * are permitted provided that the following conditions are met:<a name="line.6"></a>
<span class="sourceLineNo">007</span> *<a name="line.7"></a>
<span class="sourceLineNo">008</span> *   *  Redistributions of source code must retain the above copyright notice,<a name="line.8"></a>
<span class="sourceLineNo">009</span> *      this list of conditions and the following disclaimer.<a name="line.9"></a>
<span class="sourceLineNo">010</span> *<a name="line.10"></a>
<span class="sourceLineNo">011</span> *   *  Redistributions in binary form must reproduce the above copyright notice,<a name="line.11"></a>
<span class="sourceLineNo">012</span> *      this list of conditions and the following disclaimer in the documentation<a name="line.12"></a>
<span class="sourceLineNo">013</span> *      and/or other materials provided with the distribution.<a name="line.13"></a>
<span class="sourceLineNo">014</span> *<a name="line.14"></a>
<span class="sourceLineNo">015</span> *   *  Neither the name of the University of Southampton nor the names of its<a name="line.15"></a>
<span class="sourceLineNo">016</span> *      contributors may be used to endorse or promote products derived from this<a name="line.16"></a>
<span class="sourceLineNo">017</span> *      software without specific prior written permission.<a name="line.17"></a>
<span class="sourceLineNo">018</span> *<a name="line.18"></a>
<span class="sourceLineNo">019</span> * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND<a name="line.19"></a>
<span class="sourceLineNo">020</span> * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED<a name="line.20"></a>
<span class="sourceLineNo">021</span> * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE<a name="line.21"></a>
<span class="sourceLineNo">022</span> * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR<a name="line.22"></a>
<span class="sourceLineNo">023</span> * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES<a name="line.23"></a>
<span class="sourceLineNo">024</span> * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;<a name="line.24"></a>
<span class="sourceLineNo">025</span> * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON<a name="line.25"></a>
<span class="sourceLineNo">026</span> * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT<a name="line.26"></a>
<span class="sourceLineNo">027</span> * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS<a name="line.27"></a>
<span class="sourceLineNo">028</span> * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.<a name="line.28"></a>
<span class="sourceLineNo">029</span> */<a name="line.29"></a>
<span class="sourceLineNo">030</span>package org.openimaj.image.feature.local.aggregate;<a name="line.30"></a>
<span class="sourceLineNo">031</span><a name="line.31"></a>
<span class="sourceLineNo">032</span>import java.util.List;<a name="line.32"></a>
<span class="sourceLineNo">033</span><a name="line.33"></a>
<span class="sourceLineNo">034</span>import org.openimaj.citation.annotation.Reference;<a name="line.34"></a>
<span class="sourceLineNo">035</span>import org.openimaj.citation.annotation.ReferenceType;<a name="line.35"></a>
<span class="sourceLineNo">036</span>import org.openimaj.citation.annotation.References;<a name="line.36"></a>
<span class="sourceLineNo">037</span>import org.openimaj.feature.ArrayFeatureVector;<a name="line.37"></a>
<span class="sourceLineNo">038</span>import org.openimaj.feature.FloatFV;<a name="line.38"></a>
<span class="sourceLineNo">039</span>import org.openimaj.feature.local.LocalFeature;<a name="line.39"></a>
<span class="sourceLineNo">040</span>import org.openimaj.math.statistics.distribution.MixtureOfGaussians;<a name="line.40"></a>
<span class="sourceLineNo">041</span>import org.openimaj.math.statistics.distribution.MultivariateGaussian;<a name="line.41"></a>
<span class="sourceLineNo">042</span>import org.openimaj.ml.gmm.GaussianMixtureModelEM;<a name="line.42"></a>
<span class="sourceLineNo">043</span>import org.openimaj.ml.gmm.GaussianMixtureModelEM.CovarianceType;<a name="line.43"></a>
<span class="sourceLineNo">044</span><a name="line.44"></a>
<span class="sourceLineNo">045</span>/**<a name="line.45"></a>
<span class="sourceLineNo">046</span> * Implementation of the Fisher Vector (FV) encoding scheme. FV provides a way<a name="line.46"></a>
<span class="sourceLineNo">047</span> * of encoding a set of vectors (e.g. local features) as a single vector that<a name="line.47"></a>
<span class="sourceLineNo">048</span> * encapsulates the first and second order residuals of the vectors from a<a name="line.48"></a>
<span class="sourceLineNo">049</span> * gaussian mixture model.<a name="line.49"></a>
<span class="sourceLineNo">050</span> * &lt;p&gt;<a name="line.50"></a>
<span class="sourceLineNo">051</span> * The dimensionality of the output vector is 2*K*D where K is the number of<a name="line.51"></a>
<span class="sourceLineNo">052</span> * Gaussians in the mixture, and D is the descriptor dimensionality. Note that<a name="line.52"></a>
<span class="sourceLineNo">053</span> * only the diagonal values of the gaussian covariance matrices are used, and<a name="line.53"></a>
<span class="sourceLineNo">054</span> * thus you probably want to learn a {@link CovarianceType#Diagonal} or<a name="line.54"></a>
<span class="sourceLineNo">055</span> * {@link CovarianceType#Spherical}Â type gaussian with the<a name="line.55"></a>
<span class="sourceLineNo">056</span> * {@link GaussianMixtureModelEM} class.<a name="line.56"></a>
<span class="sourceLineNo">057</span> *<a name="line.57"></a>
<span class="sourceLineNo">058</span> * @author Jonathon Hare (jsh2@ecs.soton.ac.uk)<a name="line.58"></a>
<span class="sourceLineNo">059</span> *<a name="line.59"></a>
<span class="sourceLineNo">060</span> * @param &lt;T&gt;<a name="line.60"></a>
<span class="sourceLineNo">061</span> *            Primitive array type of the {@link ArrayFeatureVector}s used by<a name="line.61"></a>
<span class="sourceLineNo">062</span> *            the {@link LocalFeature}s that will be processed.<a name="line.62"></a>
<span class="sourceLineNo">063</span> */<a name="line.63"></a>
<span class="sourceLineNo">064</span>@References(<a name="line.64"></a>
<span class="sourceLineNo">065</span>                references = {<a name="line.65"></a>
<span class="sourceLineNo">066</span>                                @Reference(<a name="line.66"></a>
<span class="sourceLineNo">067</span>                                                type = ReferenceType.Inproceedings,<a name="line.67"></a>
<span class="sourceLineNo">068</span>                                                author = { "Perronnin, F.", "Dance, C." },<a name="line.68"></a>
<span class="sourceLineNo">069</span>                                                title = "Fisher Kernels on Visual Vocabularies for Image Categorization",<a name="line.69"></a>
<span class="sourceLineNo">070</span>                                                year = "2007",<a name="line.70"></a>
<span class="sourceLineNo">071</span>                                                booktitle = "Computer Vision and Pattern Recognition, 2007. CVPR '07. IEEE Conference on",<a name="line.71"></a>
<span class="sourceLineNo">072</span>                                                pages = { "1", "8" },<a name="line.72"></a>
<span class="sourceLineNo">073</span>                                                customData = {<a name="line.73"></a>
<span class="sourceLineNo">074</span>                                                                "keywords",<a name="line.74"></a>
<span class="sourceLineNo">075</span>                                                                "Gaussian processes;gradient methods;image classification;Fisher kernels;Gaussian mixture model;generative probability model;gradient vector;image categorization;pattern classification;visual vocabularies;Character generation;Feeds;Image databases;Kernel;Pattern classification;Power generation;Signal generators;Spatial databases;Visual databases;Vocabulary",<a name="line.75"></a>
<span class="sourceLineNo">076</span>                                                                "doi", "10.1109/CVPR.2007.383266",<a name="line.76"></a>
<span class="sourceLineNo">077</span>                                                                "ISSN", "1063-6919"<a name="line.77"></a>
<span class="sourceLineNo">078</span>                                                }<a name="line.78"></a>
<span class="sourceLineNo">079</span>                                                ),<a name="line.79"></a>
<span class="sourceLineNo">080</span>                                                @Reference(<a name="line.80"></a>
<span class="sourceLineNo">081</span>                                                                type = ReferenceType.Inproceedings,<a name="line.81"></a>
<span class="sourceLineNo">082</span>                                                                author = { "Perronnin, Florent", "S\'{a}nchez, Jorge", "Mensink, Thomas" },<a name="line.82"></a>
<span class="sourceLineNo">083</span>                                                                title = "Improving the Fisher Kernel for Large-scale Image Classification",<a name="line.83"></a>
<span class="sourceLineNo">084</span>                                                                year = "2010",<a name="line.84"></a>
<span class="sourceLineNo">085</span>                                                                booktitle = "Proceedings of the 11th European Conference on Computer Vision: Part IV",<a name="line.85"></a>
<span class="sourceLineNo">086</span>                                                                pages = { "143", "", "156" },<a name="line.86"></a>
<span class="sourceLineNo">087</span>                                                                url = "http://dl.acm.org/citation.cfm?id=1888089.1888101",<a name="line.87"></a>
<span class="sourceLineNo">088</span>                                                                publisher = "Springer-Verlag",<a name="line.88"></a>
<span class="sourceLineNo">089</span>                                                                series = "ECCV'10",<a name="line.89"></a>
<span class="sourceLineNo">090</span>                                                                customData = {<a name="line.90"></a>
<span class="sourceLineNo">091</span>                                                                                "isbn", "3-642-15560-X, 978-3-642-15560-4",<a name="line.91"></a>
<span class="sourceLineNo">092</span>                                                                                "location", "Heraklion, Crete, Greece",<a name="line.92"></a>
<span class="sourceLineNo">093</span>                                                                                "numpages", "14",<a name="line.93"></a>
<span class="sourceLineNo">094</span>                                                                                "acmid", "1888101",<a name="line.94"></a>
<span class="sourceLineNo">095</span>                                                                                "address", "Berlin, Heidelberg"<a name="line.95"></a>
<span class="sourceLineNo">096</span>                                                                }<a name="line.96"></a>
<span class="sourceLineNo">097</span>                                                                )<a name="line.97"></a>
<span class="sourceLineNo">098</span>                })<a name="line.98"></a>
<span class="sourceLineNo">099</span>public class FisherVector&lt;T&gt; implements VectorAggregator&lt;ArrayFeatureVector&lt;T&gt;, FloatFV&gt; {<a name="line.99"></a>
<span class="sourceLineNo">100</span>        private MixtureOfGaussians gmm;<a name="line.100"></a>
<span class="sourceLineNo">101</span>        private boolean hellinger;<a name="line.101"></a>
<span class="sourceLineNo">102</span>        private boolean l2normalise;<a name="line.102"></a>
<span class="sourceLineNo">103</span><a name="line.103"></a>
<span class="sourceLineNo">104</span>        /**<a name="line.104"></a>
<span class="sourceLineNo">105</span>         * Construct with the given mixture of Gaussians and optional improvement<a name="line.105"></a>
<span class="sourceLineNo">106</span>         * steps. The covariance matrices of the gaussians are all assumed to be<a name="line.106"></a>
<span class="sourceLineNo">107</span>         * diagonal, and will be treated as such; any non-zero off-diagonal values<a name="line.107"></a>
<span class="sourceLineNo">108</span>         * will be completely ignored.<a name="line.108"></a>
<span class="sourceLineNo">109</span>         *<a name="line.109"></a>
<span class="sourceLineNo">110</span>         * @param gmm<a name="line.110"></a>
<span class="sourceLineNo">111</span>         *            the mixture of gaussians<a name="line.111"></a>
<span class="sourceLineNo">112</span>         * @param hellinger<a name="line.112"></a>
<span class="sourceLineNo">113</span>         *            if true then use Hellinger's kernel rather than the linear one<a name="line.113"></a>
<span class="sourceLineNo">114</span>         *            by signed square rooting the values in the final vector<a name="line.114"></a>
<span class="sourceLineNo">115</span>         * @param l2normalise<a name="line.115"></a>
<span class="sourceLineNo">116</span>         *            if true then apply l2 normalisation to the final vector. This<a name="line.116"></a>
<span class="sourceLineNo">117</span>         *            occurs after the Hellinger step if it is used.<a name="line.117"></a>
<span class="sourceLineNo">118</span>         */<a name="line.118"></a>
<span class="sourceLineNo">119</span>        public FisherVector(MixtureOfGaussians gmm, boolean hellinger, boolean l2normalise) {<a name="line.119"></a>
<span class="sourceLineNo">120</span>                this.gmm = gmm;<a name="line.120"></a>
<span class="sourceLineNo">121</span>                this.hellinger = hellinger;<a name="line.121"></a>
<span class="sourceLineNo">122</span>                this.l2normalise = l2normalise;<a name="line.122"></a>
<span class="sourceLineNo">123</span>        }<a name="line.123"></a>
<span class="sourceLineNo">124</span><a name="line.124"></a>
<span class="sourceLineNo">125</span>        /**<a name="line.125"></a>
<span class="sourceLineNo">126</span>         * Construct the standard Fisher Vector encoder with the given mixture of<a name="line.126"></a>
<span class="sourceLineNo">127</span>         * Gaussians. The covariance matrices of the gaussians are all assumed to be<a name="line.127"></a>
<span class="sourceLineNo">128</span>         * diagonal, and will be treated as such; any non-zero off-diagonal values<a name="line.128"></a>
<span class="sourceLineNo">129</span>         * will be completely ignored.<a name="line.129"></a>
<span class="sourceLineNo">130</span>         *<a name="line.130"></a>
<span class="sourceLineNo">131</span>         * @param gmm<a name="line.131"></a>
<span class="sourceLineNo">132</span>         *            the mixture of gaussians<a name="line.132"></a>
<span class="sourceLineNo">133</span>         */<a name="line.133"></a>
<span class="sourceLineNo">134</span>        public FisherVector(MixtureOfGaussians gmm) {<a name="line.134"></a>
<span class="sourceLineNo">135</span>                this(gmm, false);<a name="line.135"></a>
<span class="sourceLineNo">136</span>        }<a name="line.136"></a>
<span class="sourceLineNo">137</span><a name="line.137"></a>
<span class="sourceLineNo">138</span>        /**<a name="line.138"></a>
<span class="sourceLineNo">139</span>         * Construct the Fisher Vector encoder with the given mixture of Gaussians<a name="line.139"></a>
<span class="sourceLineNo">140</span>         * and the optional improvement steps (in the sense of the VLFeat<a name="line.140"></a>
<span class="sourceLineNo">141</span>         * documentation). The covariance matrices of the gaussians are all assumed<a name="line.141"></a>
<span class="sourceLineNo">142</span>         * to be diagonal, and will be treated as such; any non-zero off-diagonal<a name="line.142"></a>
<span class="sourceLineNo">143</span>         * values will be completely ignored. For the improved version, the final<a name="line.143"></a>
<span class="sourceLineNo">144</span>         * vector is projected into Hellinger's kernel and then l2 normalised.<a name="line.144"></a>
<span class="sourceLineNo">145</span>         *<a name="line.145"></a>
<span class="sourceLineNo">146</span>         * @param gmm<a name="line.146"></a>
<span class="sourceLineNo">147</span>         *            the mixture of gaussians<a name="line.147"></a>
<span class="sourceLineNo">148</span>         * @param improved<a name="line.148"></a>
<span class="sourceLineNo">149</span>         *            if true then Hellinger's kernel is used, and the vector is l2<a name="line.149"></a>
<span class="sourceLineNo">150</span>         *            normalised.<a name="line.150"></a>
<span class="sourceLineNo">151</span>         */<a name="line.151"></a>
<span class="sourceLineNo">152</span>        public FisherVector(MixtureOfGaussians gmm, boolean improved) {<a name="line.152"></a>
<span class="sourceLineNo">153</span>                this(gmm, improved, improved);<a name="line.153"></a>
<span class="sourceLineNo">154</span>        }<a name="line.154"></a>
<span class="sourceLineNo">155</span><a name="line.155"></a>
<span class="sourceLineNo">156</span>        @Override<a name="line.156"></a>
<span class="sourceLineNo">157</span>        public FloatFV aggregate(List&lt;? extends LocalFeature&lt;?, ? extends ArrayFeatureVector&lt;T&gt;&gt;&gt; features) {<a name="line.157"></a>
<span class="sourceLineNo">158</span>                if (features == null || features.size() &lt;= 0)<a name="line.158"></a>
<span class="sourceLineNo">159</span>                        return null;<a name="line.159"></a>
<span class="sourceLineNo">160</span><a name="line.160"></a>
<span class="sourceLineNo">161</span>                final int K = this.gmm.gaussians.length;<a name="line.161"></a>
<span class="sourceLineNo">162</span>                final int D = features.get(0).getFeatureVector().length();<a name="line.162"></a>
<span class="sourceLineNo">163</span><a name="line.163"></a>
<span class="sourceLineNo">164</span>                final float[] vector = new float[2 * K * D];<a name="line.164"></a>
<span class="sourceLineNo">165</span><a name="line.165"></a>
<span class="sourceLineNo">166</span>                // cache all the features in an array<a name="line.166"></a>
<span class="sourceLineNo">167</span>                final double[][] X = new double[features.size()][];<a name="line.167"></a>
<span class="sourceLineNo">168</span>                for (int i = 0; i &lt; X.length; i++) {<a name="line.168"></a>
<span class="sourceLineNo">169</span>                        final LocalFeature&lt;?, ? extends ArrayFeatureVector&lt;T&gt;&gt; f = features.get(i);<a name="line.169"></a>
<span class="sourceLineNo">170</span>                        X[i] = f.getFeatureVector().asDoubleVector();<a name="line.170"></a>
<span class="sourceLineNo">171</span>                }<a name="line.171"></a>
<span class="sourceLineNo">172</span><a name="line.172"></a>
<span class="sourceLineNo">173</span>                return computeFisherVector(features.size(), K, D, vector, X);<a name="line.173"></a>
<span class="sourceLineNo">174</span>        }<a name="line.174"></a>
<span class="sourceLineNo">175</span><a name="line.175"></a>
<span class="sourceLineNo">176</span>        @Override<a name="line.176"></a>
<span class="sourceLineNo">177</span>        public FloatFV aggregateVectors(List&lt;? extends ArrayFeatureVector&lt;T&gt;&gt; features) {<a name="line.177"></a>
<span class="sourceLineNo">178</span>                if (features == null || features.size() &lt;= 0)<a name="line.178"></a>
<span class="sourceLineNo">179</span>                        return null;<a name="line.179"></a>
<span class="sourceLineNo">180</span><a name="line.180"></a>
<span class="sourceLineNo">181</span>                final int K = this.gmm.gaussians.length;<a name="line.181"></a>
<span class="sourceLineNo">182</span>                final int D = features.get(0).length();<a name="line.182"></a>
<span class="sourceLineNo">183</span><a name="line.183"></a>
<span class="sourceLineNo">184</span>                final float[] vector = new float[2 * K * D];<a name="line.184"></a>
<span class="sourceLineNo">185</span><a name="line.185"></a>
<span class="sourceLineNo">186</span>                // cache all the features in an array<a name="line.186"></a>
<span class="sourceLineNo">187</span>                final double[][] X = new double[features.size()][];<a name="line.187"></a>
<span class="sourceLineNo">188</span>                for (int i = 0; i &lt; X.length; i++) {<a name="line.188"></a>
<span class="sourceLineNo">189</span>                        final ArrayFeatureVector&lt;T&gt; f = features.get(i);<a name="line.189"></a>
<span class="sourceLineNo">190</span>                        X[i] = f.asDoubleVector();<a name="line.190"></a>
<span class="sourceLineNo">191</span>                }<a name="line.191"></a>
<span class="sourceLineNo">192</span><a name="line.192"></a>
<span class="sourceLineNo">193</span>                return computeFisherVector(features.size(), K, D, vector, X);<a name="line.193"></a>
<span class="sourceLineNo">194</span>        }<a name="line.194"></a>
<span class="sourceLineNo">195</span><a name="line.195"></a>
<span class="sourceLineNo">196</span>        private FloatFV computeFisherVector(int nFeatures, final int K,<a name="line.196"></a>
<span class="sourceLineNo">197</span>                        final int D, final float[] vector, final double[][] X)<a name="line.197"></a>
<span class="sourceLineNo">198</span>        {<a name="line.198"></a>
<span class="sourceLineNo">199</span>                // compute posterior probabilities of all features at once (more<a name="line.199"></a>
<span class="sourceLineNo">200</span>                // efficient than<a name="line.200"></a>
<span class="sourceLineNo">201</span>                // doing it for each one at a time)<a name="line.201"></a>
<span class="sourceLineNo">202</span>                final double[][] posteriors = gmm.scoreSamples(X).secondObject();<a name="line.202"></a>
<span class="sourceLineNo">203</span><a name="line.203"></a>
<span class="sourceLineNo">204</span>                for (int p = 0; p &lt; X.length; p++) {<a name="line.204"></a>
<span class="sourceLineNo">205</span>                        final double[] xp = X[p];<a name="line.205"></a>
<span class="sourceLineNo">206</span><a name="line.206"></a>
<span class="sourceLineNo">207</span>                        for (int k = 0; k &lt; K; k++) {<a name="line.207"></a>
<span class="sourceLineNo">208</span>                                final double apk = posteriors[p][k];<a name="line.208"></a>
<span class="sourceLineNo">209</span><a name="line.209"></a>
<span class="sourceLineNo">210</span>                                if (apk &lt; 1e-6)<a name="line.210"></a>
<span class="sourceLineNo">211</span>                                        continue; // speed-up: ignore really small terms...<a name="line.211"></a>
<span class="sourceLineNo">212</span><a name="line.212"></a>
<span class="sourceLineNo">213</span>                                final MultivariateGaussian gauss = gmm.gaussians[k];<a name="line.213"></a>
<span class="sourceLineNo">214</span>                                final double[] mean = gauss.getMean().getArray()[0];<a name="line.214"></a>
<span class="sourceLineNo">215</span><a name="line.215"></a>
<span class="sourceLineNo">216</span>                                for (int j = 0; j &lt; D; j++) {<a name="line.216"></a>
<span class="sourceLineNo">217</span>                                        final double var = gauss.getCovariance(j, j);<a name="line.217"></a>
<span class="sourceLineNo">218</span>                                        final double diff = (xp[j] - mean[j]) / Math.sqrt(var);<a name="line.218"></a>
<span class="sourceLineNo">219</span><a name="line.219"></a>
<span class="sourceLineNo">220</span>                                        vector[k * 2 * D + j] += apk * diff;<a name="line.220"></a>
<span class="sourceLineNo">221</span>                                        vector[k * 2 * D + j + D] += apk * ((diff * diff) - 1);<a name="line.221"></a>
<span class="sourceLineNo">222</span>                                }<a name="line.222"></a>
<span class="sourceLineNo">223</span>                        }<a name="line.223"></a>
<span class="sourceLineNo">224</span>                }<a name="line.224"></a>
<span class="sourceLineNo">225</span><a name="line.225"></a>
<span class="sourceLineNo">226</span>                for (int k = 0; k &lt; K; k++) {<a name="line.226"></a>
<span class="sourceLineNo">227</span>                        final double wt1 = 1.0 / (nFeatures * Math.sqrt(gmm.weights[k]));<a name="line.227"></a>
<span class="sourceLineNo">228</span>                        final double wt2 = 1.0 / (nFeatures * Math.sqrt(2 * gmm.weights[k]));<a name="line.228"></a>
<span class="sourceLineNo">229</span><a name="line.229"></a>
<span class="sourceLineNo">230</span>                        for (int j = 0; j &lt; D; j++) {<a name="line.230"></a>
<span class="sourceLineNo">231</span>                                vector[k * 2 * D + j] *= wt1;<a name="line.231"></a>
<span class="sourceLineNo">232</span>                                vector[k * 2 * D + j + D] *= wt2;<a name="line.232"></a>
<span class="sourceLineNo">233</span>                        }<a name="line.233"></a>
<span class="sourceLineNo">234</span>                }<a name="line.234"></a>
<span class="sourceLineNo">235</span><a name="line.235"></a>
<span class="sourceLineNo">236</span>                final FloatFV out = new FloatFV(vector);<a name="line.236"></a>
<span class="sourceLineNo">237</span><a name="line.237"></a>
<span class="sourceLineNo">238</span>                if (hellinger) {<a name="line.238"></a>
<span class="sourceLineNo">239</span>                        for (int i = 0; i &lt; out.values.length; i++) {<a name="line.239"></a>
<span class="sourceLineNo">240</span>                                out.values[i] = (float) (out.values[i] &gt; 0 ? Math.sqrt(out.values[i]) :<a name="line.240"></a>
<span class="sourceLineNo">241</span>                                        -1 * Math.sqrt(-1 * out.values[i]));<a name="line.241"></a>
<span class="sourceLineNo">242</span>                        }<a name="line.242"></a>
<span class="sourceLineNo">243</span>                }<a name="line.243"></a>
<span class="sourceLineNo">244</span><a name="line.244"></a>
<span class="sourceLineNo">245</span>                if (l2normalise) {<a name="line.245"></a>
<span class="sourceLineNo">246</span>                        // l2 norm<a name="line.246"></a>
<span class="sourceLineNo">247</span>                        double sumsq = 0;<a name="line.247"></a>
<span class="sourceLineNo">248</span>                        for (int i = 0; i &lt; out.values.length; i++) {<a name="line.248"></a>
<span class="sourceLineNo">249</span>                                sumsq += (out.values[i] * out.values[i]);<a name="line.249"></a>
<span class="sourceLineNo">250</span>                        }<a name="line.250"></a>
<span class="sourceLineNo">251</span>                        final float norm = (float) (1.0 / Math.sqrt(sumsq));<a name="line.251"></a>
<span class="sourceLineNo">252</span>                        for (int i = 0; i &lt; out.values.length; i++) {<a name="line.252"></a>
<span class="sourceLineNo">253</span>                                out.values[i] *= norm;<a name="line.253"></a>
<span class="sourceLineNo">254</span>                        }<a name="line.254"></a>
<span class="sourceLineNo">255</span>                }<a name="line.255"></a>
<span class="sourceLineNo">256</span>                return out;<a name="line.256"></a>
<span class="sourceLineNo">257</span>        }<a name="line.257"></a>
<span class="sourceLineNo">258</span>}<a name="line.258"></a>




























































</pre>
</div>
</body>
</html>